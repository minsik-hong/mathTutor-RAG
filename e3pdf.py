import os
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ğŸ” Load API key
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY").strip()

# ğŸ“ íŒŒì¼ ê²½ë¡œ
PDF_FILE = "data/e3.pdf"
CHROMA_DB_DIR = "db/chroma_e3"

# 1ï¸âƒ£ PDF ë¬¸ì„œ ë¡œë“œ
def load_pdf(path):
    loader = PyPDFLoader(path)
    documents = loader.load()
    return documents

# 2ï¸âƒ£ ë¬¸ì„œ ë¶„í•  - ìˆ˜í•™ êµê³¼ì„œì— ë§ê²Œ ë¬¸ë§¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
def split_documents(docs):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=600,
        chunk_overlap=50,
        separators=["\n\n", "\n", ".", "?", "!", "â‹¯â‹¯", "â–¶", "í™œë™", "ì˜ˆì œ", "ë¬¸ì œ", "ì‹", "=", "+", "-"]
    )
    return text_splitter.split_documents(docs)

# 3ï¸âƒ£ ë¬¸ì„œë¥¼ ë²¡í„° DBì— ì €ì¥
def save_to_vector_db(docs, persist_dir=CHROMA_DB_DIR):
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma.from_documents(
        docs, embedding=embeddings,
        persist_directory=persist_dir,
        collection_name="elementary-math"
    )
    vectordb.persist()
    return vectordb

# 4ï¸âƒ£ ì €ì¥ëœ ë²¡í„° DB ë¡œë“œ
def load_vector_db(persist_dir=CHROMA_DB_DIR):
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma(
        persist_directory=persist_dir,
        embedding_function=embeddings,
        collection_name="elementary-math"
    )
    return vectordb

# 5ï¸âƒ£ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸°
def ask_question(vectordb, question):
    retriever = vectordb.as_retriever(search_kwargs={"k": 5})

    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(
            model_name="gpt-3.5-turbo-16k",
            temperature=0.3,
            openai_api_key=OPENAI_API_KEY
        ),
        chain_type="map_reduce",
        retriever=retriever,
        return_source_documents=True
    )

    result = qa_chain({"query": question})
    return result["result"]

if __name__ == "__main__":
    # Step 1: ë¬¸ì„œ ë¡œë“œ
    print("ğŸ“„ PDF ë¡œë“œ ì¤‘...")
    documents = load_pdf(PDF_FILE)
    print(f"ì´ {len(documents)}ê°œì˜ raw ë¬¸ì„œê°€ ë¡œë“œë¨.")

    # Step 2: ë¬¸ì„œ ë¶„í• 
    print("ğŸ§  ë¬¸ì„œ ë¶„í•  ì¤‘...")
    split_docs = split_documents(documents)
    print(f"â¡ï¸ ì´ {len(split_docs)}ê°œì˜ ë¬¸ì„œ chunk ìƒì„±ë¨.")

    # Step 3: ë²¡í„° DB ì €ì¥
    vectordb = save_to_vector_db(split_docs)
    print("âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ")

    # Step 4: ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
    question = "ì´ˆë“±í•™êµ 3í•™ë…„ ìˆ˜ì¤€ì— ë§ë„ë¡, ê³±ì…ˆì— ëŒ€í•œ ì„¤ëª…ê³¼ ì˜ˆì œë¥¼ ì•Œë ¤ì¤˜."
    answer = ask_question(vectordb, question)
    print("ğŸ“Œ ì§ˆë¬¸:", question)
    print("ğŸ’¡ ë‹µë³€:", answer)
