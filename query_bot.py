# query_bot.py
import os
from dotenv import load_dotenv
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# API í‚¤ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY").strip()

CHROMA_DB_DIR = "db/chroma_e3"

def load_vector_db(persist_dir=CHROMA_DB_DIR):
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma(
        persist_directory=persist_dir,
        embedding_function=embeddings,
        collection_name="elementary-math"
    )
    return vectordb

def ask_question(vectordb, question):
    retriever = vectordb.as_retriever(search_kwargs={"k": 5})

    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(
            model_name="gpt-3.5-turbo-16k",
            temperature=0.3,
            openai_api_key=OPENAI_API_KEY
        ),
        chain_type="map_reduce",
        retriever=retriever,
        return_source_documents=True
    )

    result = qa_chain({"query": question})
    return result["result"]

if __name__ == "__main__":
    print("ğŸ“‚ ë²¡í„° DB ë¡œë“œ ì¤‘...")
    vectordb = load_vector_db()

    # ğŸ‘‰ ì—¬ê¸°ì„œ ì§ˆë¬¸ ë°”ê¿”ê°€ë©° í…ŒìŠ¤íŠ¸!
    question = "ì´ˆë“±í•™êµ 3í•™ë…„ ìˆ˜ì¤€ì— ë§ê²Œ ë¶„ìˆ˜ì˜ í¬ê¸° ë¹„êµ ë°©ë²•ì„ ì•Œë ¤ì¤˜."
    answer = ask_question(vectordb, question)

    print("ğŸ“Œ ì§ˆë¬¸:", question)
    print("ğŸ’¡ ë‹µë³€:", answer)
