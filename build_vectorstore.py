import os
import json
from dotenv import load_dotenv
from langchain.schema import Document
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import OpenAIEmbeddings

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY").strip()

# âœ… í´ë” ê²½ë¡œ
JSON_FOLDER = "data/jsons"
PDF_FOLDER = "data/pdfs"
IMG_JSON_FOLDER = "data/image_jsons"
IMG_FOLDER = "data/images"
CHROMA_DB_DIR = "db/chroma_math_json"

# âœ… ì•ˆì „í•œ ë¬¸ìì—´ ë³€í™˜
def safe_str(value):
    return "" if value is None else str(value)

# âœ… ê°œë… ì„¤ëª… JSON ë¡œë”©
def load_json_documents(folder_path):
    documents = []

    for filename in os.listdir(folder_path):
        if not filename.endswith(".json"):
            continue

        file_path = os.path.join(folder_path, filename)

        # 
        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
            data = json.load(f)

        for concept_id, concept_data in raw_data.items():
            for key in ["fromConcept", "toConcept"]:
                concept = concept_data.get(key, {})
                if not concept:
                    continue

                content = f"{concept.get('name')}\n\n{concept.get('description', '')}"
                metadata = {
                    "concept_id": safe_str(concept.get("id")),
                    "semester": safe_str(concept.get("semester")),
                    "chapter_id": safe_str(concept.get("chapter", {}).get("id")),
                    "chapter_name": safe_str(concept.get("chapter", {}).get("name")),
                    "achievement_id": safe_str(concept.get("achievement", {}).get("id")),
                    "achievement_name": safe_str(concept.get("achievement", {}).get("name")),
                    "relation_type": key,
                    "parent_id": safe_str(concept_id),
                    "source": filename
                }

                documents.append(Document(page_content=content, metadata=metadata))

    return documents

# âœ… PDF ë¬¸ì„œ ë¡œë”©
def load_pdf_documents(folder_path):
    documents = []

    for filename in os.listdir(folder_path):
        if not filename.endswith(".pdf"):
            continue

        file_path = os.path.join(folder_path, filename)
        loader = PyPDFLoader(file_path)
        pdf_docs = loader.load()

        for doc in pdf_docs:
            doc.metadata["source"] = filename

        documents.extend(pdf_docs)

    return documents

# âœ… ì´ë¯¸ì§€ ê¸°ë°˜ JSON ë¡œë”© (í•˜ìœ„ í´ë” í¬í•¨)
def load_image_json_documents(folder_path, image_folder):
    documents = []

    for root, _, files in os.walk(folder_path):  # í•˜ìœ„ í´ë”ê¹Œì§€ íƒìƒ‰
        for filename in files:
            if not filename.endswith(".json"):
                continue

            file_path = os.path.join(root, filename)
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            # OCR í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            question_text = data["OCR_info"][0].get("question_text", "")
            image_filename = data.get("question_filename", "")

            # ì´ë¯¸ì§€ ê²½ë¡œ ì°¾ê¸° (image_folder í•˜ìœ„ ì „ì²´ì—ì„œ ê²€ìƒ‰)
            image_path = None
            for img_root, _, img_files in os.walk(image_folder):
                if image_filename in img_files:
                    image_path = os.path.join(img_root, image_filename)
                    break

            info = data.get("question_info", [{}])[0]  # ì²« ë²ˆì§¸ question_info ì‚¬ìš©

            metadata = {
                "id": data.get("id", ""),
                "question_topic": info.get("question_topic_name", ""),
                "question_grade": info.get("question_grade", ""),
                "question_type": info.get("question_type1", ""),
                "question_topic_name": info.get("question_topic_name", ""),
                "difficulty": info.get("question_difficulty", ""),
                "step": info.get("question_step", ""),
                "image_path": image_path or "ê²½ë¡œ ì—†ìŒ",
                "source": filename
            }

            documents.append(Document(page_content=question_text, metadata=metadata))

    return documents

# âœ… ë²¡í„° DBì— ì €ì¥
def save_to_vector_db(docs, persist_dir=CHROMA_DB_DIR):
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma.from_documents(docs, embedding=embeddings, persist_directory=persist_dir)
    vectordb.persist()
    return vectordb

# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    json_docs = load_json_documents(JSON_FOLDER)
    print(f"âœ… ê°œë… JSON ë¬¸ì„œ {len(json_docs)}ê°œ ë¡œë“œ ì™„ë£Œ")

    pdf_docs = load_pdf_documents(PDF_FOLDER)
    print(f"âœ… PDF ë¬¸ì„œ {len(pdf_docs)}ê°œ ë¡œë“œ ì™„ë£Œ")

    image_json_docs = load_image_json_documents(IMG_JSON_FOLDER, IMG_FOLDER)
    print(f"âœ… ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì œ ë¬¸ì„œ {len(image_json_docs)}ê°œ ë¡œë“œ ì™„ë£Œ")

    all_docs = json_docs + pdf_docs + image_json_docs
    print(f"ğŸ“š ì´ ë¬¸ì„œ ìˆ˜: {len(all_docs)}")

    save_to_vector_db(all_docs)
    print("âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ")
